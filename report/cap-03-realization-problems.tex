
\chapter{AR specific problems regarding realization}

\section{Hardware}

Before going into detail about the hardware components of uFixit, we first have to specify the requirements, which the hardware has to fulfill. Firstly, the hardware has to be mobile, so that the user can take the instructions to the item he wants to repair. This is especially important, if the item in question is too heavy to be moved, or is firmly mounted to its location. Therefore, the uFixit hardware has to be small and light enough to be carried around, and also has to assemble and disassemble quickly.
This also rules out head tracking systems for the augmented experience, which require the installation of tracking cameras around the user to follow his head movements. Instead, a high resolution rgb camera is used for the object detection and an optional depth camera provides the exact distance between the observed object and the uFixit hardware.
Another important factor is, that many repairing tasks, require both hands to be executed. Therefore, the augmented reality device has to be mountable to the head, so that the user can see the instruction manual all the time, without holding it in one hand. This also leads to a lightweight hardware solution, as the whole weight is carried only by the head.
If the current step of the instruction set was completed by the user, the next step is selected by simple speech commands. Speech control is the only suitable way for navigating through an uFixit manual, because it requires no hand interaction and therefore lets the user concentrate on the task. This means, that the hardware also has to supply a microphone to pick up the user commands.
The last requirement, regarding the hardware power of the device, is a not very restrictive. As uFixit essentially only replays previously defined sequences of markers and overlays, the main computational effort lies in the real time object detection to match those augmentations with the real world. This task is already executed by the hardware used in today’s mobile phones and therefore  is not a limitation for the hardware selection process.

Next we propose two already existing hardware solutions, which are guarantied to be compatible with the uFixit application. The first one is the "Meta 2" a lightweight optical see through glass with an integraded 720p camera and a 3D depth sensor. It also has additional sensors for head movement tracking, which supports the optical camera tracking via sensor fusion. The downside is, that the "Meta 2" has no integrated processor and has to be connected to an external PC. It also has no internal microphone, which however is no problem, as an additional microphone can be connected to the computer.
Other optical see though glasses are of course also possible candidates for uFixit, as long as they have at least a camera, which is HD-ready, microphone support and enough processing power for the application.

The second class of supported hardware are mobile phones, especially in combination with projects like "Google Cardboard", which transform the phones to augmented reality glasses. The big advantage of mobile phones is, that they are already very common, and therefore uFixit can be used by many people without spending extra money on additional hardware. Recent smart phones also meet all the basic requirements for our application, as they already include high resolution cameras, sufficient computational power and a microphone for user input. We would also like to emphasize that devices, which are certified by Google's "Project Tango" are especially suited for uFixit, as those devices provide an additional depth camera for an even better user experience.
				

\section{Software (computer vison part)}
	      - Objekterkennung für Erstellung der Anleitung
			- Zusätzliche Marker für Erkennung ?
			- Feature matching (Nutzer bestimmte Geräteperspektiven vorgeben)
			- Schwierig: Defektes/Deformiertes Gerät erkennen
			- Manuelle Auswahl (?)

\subsection{Software (manual creation, manufacturer)}
		- complicated 3D CAD software

\subsection{Software (manual creation, end user)}
		- Einbindung von Zeigern, Animationen, Text, ...
		- Fertige Animationen (Schraube die sich raus dreht)
		- Wie im Raum platzieren
		- Prototype concept
			- Example pictures how the software looks like

\subsection{Live support}
		- Highlighting, Arrows, Painting, Audio